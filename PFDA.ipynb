{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programing for data analytics project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "• Analyse CO2 vs Temperature Anomaly from 800kyrs – present.\n",
    "• Examine one other (paleo/modern) features (e.g. CH4 or polar ice-coverage)\n",
    "• Examine Irish context:\n",
    "o Climate change signals: (see Maynooth study: The emergence of a climate change\n",
    "signal in long-term Irish meteorological observations - ScienceDirect)\n",
    "• Fuse and analyse data from various data sources and format fused data set as a pandas\n",
    "dataframe and export to csv and json formats\n",
    "• For all of the above variables, analyse the data, the trends and the relationships between\n",
    "them (temporal leads/lags/frequency analysis).\n",
    "• Predict global temperature anomaly over next few decades (synthesise data) and compare to\n",
    "published climate models if atmospheric CO2 trends continue\n",
    "• Comment on accelerated warming based on very latest features (e.g. temperature/polar-icecoverage)\n",
    "Use a Jupyter notebook for your analysis and track your progress using GitHub.\n",
    "Use an academic referencing style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import signal\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data and reading the file \n",
    "this code loads data from an Excel file into two separate pandas DataFrames (CO2_LUTHI and CO2_LUTHI_new). Each DataFrame corresponds to a specific sheet in the Excel file, and the data can then be analyzed and manipulated using pandas functionalities. The file path and sheet names are specified using raw string literals to handle any potential issues with escape characters or special characters in the file path.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO2_LUTHI = pd.read_excel(\n",
    "    r'C:\\Users\\fifoa\\OneDrive\\Desktop\\ATU\\PFDA-PROJECT-2\\CO2 LUTHI.xls', sheet_name='2.  Vostok-TD-Dome C')\n",
    "CO2_LUTHI_new = pd.read_excel(\n",
    "    r'C:\\Users\\fifoa\\OneDrive\\Desktop\\ATU\\PFDA-PROJECT-2\\CO2 LUTHI.xls', sheet_name='1.  new CO2 data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data extraction and slicing  DataFrames \n",
    "slicing_params is a list of tuples where each tuple contains the slicing parameters for one DataFrame. The loop iterates through these parameters, extracts the corresponding subset from CO2_LUTHI or CO2_LUTHI_new, and appends the subset to the resulting_dfs list. Finally, the resulting DataFrames are assigned to separate variables with meaningful names.\n",
    "\n",
    "Data Extraction and Slicing from CO2 LUTHI DataFrames\"\n",
    "\"DataFrame Slicing for Multiple Variables in CO2 LUTHI Data\"\n",
    "\"Subset Creation from CO2 LUTHI and CO2 LUTHI New DataFrames\"\n",
    "\"Analysis: Extracting Specific Data from CO2 LUTHI and CO2 LUTHI New\"\n",
    "\"Data Exploration: Selecting Subsets from CO2 LUTHI and CO2 LUTHI New\"\n",
    "\n",
    "\n",
    "This approach makes it easy to add or modify slicing parameters without duplicating code for each DataFrame extraction.\n",
    "\n",
    "EXAMPLE FROM THE BELOW IS USED TO CREATE BELOW\n",
    "https://stackoverflow.com/questions/1335392/iteration-over-list-slices\n",
    "\n",
    "https://medium.com/probably-programming/python-slicing-looping-and-copying-a-list-a2ad96a170ba#:~:text=You%20can%20use%20a%20slice%20in%20a%20for,of%20the%20office%20are%3A%20%3E%3E%3E%20Michael%20%3E%3E%3E%20Dwight\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming CO2_LUTHI and CO2_LUTHI_new are already defined\n",
    "\n",
    "slicing_params = [\n",
    "    (6, 189, 1, 3),       # monnin_luthi\n",
    "    (19, 353, 5, 7),      # pettit_luthi\n",
    "    (6, 26, 16, 18),      # siegenthaler_1_luthi\n",
    "    (6, 328, 12, 14),     # siegenthaler_2_luthi\n",
    "    (16, 253, 1, 3)       # luthi_luthi\n",
    "]\n",
    "\n",
    "resulting_dfs = []\n",
    "\n",
    "for start_row, end_row, start_col, end_col in slicing_params:\n",
    "    subset = CO2_LUTHI.iloc[start_row:end_row, start_col:end_col]\n",
    "    resulting_dfs.append(subset)\n",
    "\n",
    "# Naming the resulting DataFrames\n",
    "monnin_luthi, pettit_luthi, siegenthaler_1_luthi, siegenthaler_2_luthi, luthi_luthi = resulting_dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACING NAMES AND RENAMING COLUMNS \n",
    "\n",
    "\n",
    "This loop dynamically renames the columns based on the number of columns in each subset. It uses a list comprehension to create logical column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "slicing_params = [\n",
    "    (6, 189, 1, 3),       # monnin_luthi\n",
    "    (19, 353, 5, 7),      # pettit_luthi\n",
    "    (6, 26, 16, 18),      # siegenthaler_1_luthi\n",
    "    (6, 328, 12, 14),     # siegenthaler_2_luthi\n",
    "    (16, 253, 1, 3)       # luthi_luthi\n",
    "]\n",
    "\n",
    "resulting_dfs = []\n",
    "\n",
    "for start_row, end_row, start_col, end_col in slicing_params:\n",
    "    subset = CO2_LUTHI.iloc[start_row:end_row, start_col:end_col]\n",
    "    \n",
    "    # Assuming logical column names, replace with your actual logical column names\n",
    "    logical_column_names = [f'Column_{i}' for i in range(subset.shape[1])]\n",
    "    subset.columns = logical_column_names\n",
    "    \n",
    "    resulting_dfs.append(subset)\n",
    "\n",
    "# Naming the resulting DataFrames\n",
    "monnin_luthi, pettit_luthi, siegenthaler_1_luthi, siegenthaler_2_luthi, luthi_luthi = resulting_dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating  columns that calculates the number of years before 2023 creating colunms and removing any rows with null  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_year_data(sample):\n",
    "    # Calculate 'years_before_2023' and 'year'\n",
    "    sample['years_before_2023'] = 2023 - (1950 - sample['yr_bp'])\n",
    "    sample['year'] = 1950 - sample['yr_bp']\n",
    "    \n",
    "    # Drop the 'yr_bp' column\n",
    "    sample = sample.drop('yr_bp', axis=1)\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    sample = sample.dropna(axis=0)\n",
    "    \n",
    "    return sample\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
